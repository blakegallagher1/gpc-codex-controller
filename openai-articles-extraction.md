# OpenAI Articles — Complete Extraction for Project Reference

> Extracted from 7 OpenAI blog posts and developer documentation. Every actionable insight, architecture decision, pattern, and lesson captured for building world-class agent-driven software.

---

## ARTICLE 1: Harness Engineering — Leveraging Codex in an Agent-First World

**Source:** [openai.com/index/harness-engineering](https://openai.com/index/harness-engineering/)

### Project Context

- First commit to an empty repository landed in late August 2025
- Initial scaffold (repo structure, CI configuration, formatting rules, package manager setup, application framework) was generated by Codex CLI using GPT-5, guided by a small set of existing templates
- Even the initial AGENTS.md file was itself written by Codex — no pre-existing human-written code
- Five months later: ~1 million lines of code, ~1,500 PRs opened and merged
- Small team of just 3 engineers driving Codex → average throughput of 3.5 PRs per engineer per day
- Throughput *increased* as the team grew to 7 engineers

### Core Philosophy: No Manually-Written Code

- Humans never directly contributed any code — this became a core philosophy
- The lack of hands-on coding introduced a different kind of engineering work: **systems, scaffolding, and leverage**
- The primary job of the engineering team became enabling the agents to do useful work
- This is "harness engineering" — the discipline of designing environments, specifying intent, and building feedback loops that allow agents to do reliable work

### Key Lesson: Give Codex a Map, Not a 1,000-Page Instruction Manual

- Instead of treating AGENTS.md as the encyclopedia, treat it as the **table of contents**
- A short AGENTS.md (~100 lines) is injected into context and serves primarily as a map, with pointers to deeper sources of truth elsewhere
- The repository's knowledge base lives in a structured `docs/` directory treated as the system of record

### Knowledge Accessibility Principle

- **From the agent's point of view, anything it can't access in-context while running effectively doesn't exist**
- Knowledge that lives in Google Docs, chat threads, or people's heads is NOT accessible to the system
- All critical knowledge must be codified in the repository itself

### Documentation Enforcement

- Dedicated linters and CI jobs validate that the knowledge base is up to date, cross-linked, and structured correctly
- A recurring **"doc-gardening" agent** scans for stale or obsolete documentation that does not reflect the real code behavior and opens fix-up PRs automatically
- Because the repository is entirely agent-generated, it's optimized first for Codex's legibility

### Working Depth-First

- Early progress was slower than expected — not because Codex was incapable, but because the environment was underspecified
- The agent lacked the tools, abstractions, and internal structure required to make progress toward high-level goals
- In practice: work **depth-first** — break down larger goals into smaller building blocks (design, code, review, test), prompt the agent to construct those blocks, then use them to unlock more complex tasks
- Build foundational abstractions first, then layer complexity on top

---

## ARTICLE 2: Shell + Skills + Compaction — Tips for Long-Running Agents

**Source:** [developers.openai.com/blog/skills-shell-tips](https://developers.openai.com/blog/skills-shell-tips)

### Mental Model

**Skills = "Procedures" the model can load on demand.** A skill is a bundle of files plus a SKILL.md manifest containing frontmatter and instructions. Think: a versioned playbook the model can consult when it's time to do real work. The platform exposes each skill's name, description, and path to the model, which decides whether to invoke it.

**Shell tool = "Execution" for agents.** The shell tool lets models work inside a real terminal environment — either hosted containers managed by OpenAI or a local shell runtime you execute yourself. Hosted shell runs through the Responses API with stateful work, tool calls, multi-turn continuation, and artifacts.

**Compaction = Keep long runs moving.** Server-side compaction manages the context window and compresses conversation history automatically when context crosses the threshold.

### Why They're Better Together

- Skills reduce prompt spaghetti by moving stable procedures and examples into a reusable bundle
- Shell provides a full execution environment for installing code, running scripts, and writing outputs
- Compaction preserves continuity on long runs without manual context surgery
- Together: repeatable workflows with real execution, without turning the system prompt into a brittle megadoc

### 10 Tips and Tricks

**1. Write skill descriptions like routing logic, not marketing copy.** Your skill's description is the model's decision boundary. It should answer: When should I use this? When should I NOT? What are the outputs and success criteria? Include a "Use when vs. don't use when" block.

**2. Add negative examples and edge cases to reduce misfires.** Making skills available can initially *reduce* correct triggering. Fix: negative examples plus edge case coverage. Write explicit "Don't call this skill when…" cases. Glean saw skill-based routing initially drop triggering by ~20%, then recovered after adding negative examples.

**3. Put templates and examples inside the skill (free when unused).** Stop cramming templates into the system prompt. Templates inside skills are available exactly when needed and don't inflate tokens for unrelated queries. Glean reported biggest quality and latency gains from this pattern.

**4. Design for long runs early with container reuse and compaction.** Long-horizon agents rarely succeed as one-shot prompts. Reuse the same container across steps for stable dependencies, cached files, and intermediate outputs. Pass `previous_response_id` for same-thread continuation. Use compaction as a default primitive, not an emergency fallback.

**5. When you need determinism, explicitly tell the model to use the skill.** Default: model decides when to use a skill. For production workflows with clear contracts: just say "Use the `<skill name>` skill." This turns fuzzy routing into an explicit contract — simplest reliability lever.

**6. Treat skills + networking as a high-risk combo (design for containment).** Combining skills with open network access creates a **high-risk path for data exfiltration**. Keep network allowlists strict, assume tool output is untrusted, avoid open internet + powerful procedures in consumer-facing flows. Default posture: Skills allowed, Shell allowed, Network enabled only with minimal allowlist.

**7. Make `/mnt/data` your handoff boundary for artifacts.** For hosted shell workflows, treat `/mnt/data` as the standard place to write outputs. Mental model: tools write to disk, models reason over disk, developers retrieve from disk.

**8. Understand allowlists as a two-layer system.** Org-level allowlist (admin sets max allowed destinations) and request-level `network_policy` (must be subset of org allowlist). Keep org allowlist small and stable; keep request allowlists even smaller.

**9. Use `domain_secrets` for authenticated calls.** Model sees placeholders (e.g., `$API_KEY`), sidecar injects real values only for approved destinations. Strong default for any agent calling a protected API from within a container.

**10. Use the same APIs in the cloud and locally.** Skills work with hosted and local shell. Local execution mode: you execute `shell_call` yourself and return `shell_call_output`. Dev loop: Start local (fast iteration) → Move to hosted containers (repeatability, isolation) → Keep skills the same across both modes.

### Three Build Patterns

**Pattern A: Install → Fetch → Write Artifact.** Install dependencies, scrape or call an API, write a report to `/mnt/data/report.md`. Creates a clean review boundary: show artifact to user, log it, diff it, or feed into later step.

**Pattern B: Skills + Shell for Repeatable Workflows.** Encode workflow (steps, guardrails, templates) in a skill → Mount skill into shell environment → Agent follows skill to produce artifacts deterministically. Effective for: spreadsheet analysis, dataset cleaning, standardized report generation.

**Pattern C: Skills as Enterprise Workflow Carriers.** Skills close the accuracy gap between single tool invocation and multi-tool orchestration by making tool reasoning more procedural. Glean example: Salesforce-oriented skill increased eval accuracy from **73% → 85%** and reduced time-to-first-token by **18.1%**. Skills become living SOPs: updated as your org evolves, executed consistently by agents.

---

## ARTICLE 3: 15 Lessons Building ChatGPT Apps

**Source:** [developers.openai.com/blog/15-lessons-building-chatgpt-apps](https://developers.openai.com/blog/15-lessons-building-chatgpt-apps)

### The Three Body Problem

Traditional web apps: user + UI. ChatGPT apps introduce a third body: **the model**. Managing information flow between this trio is the hardest part. This creates **context asymmetry** — each body has partial knowledge, and no single one has the full picture.

### Lesson 1: Not All Context Should Be Shared

- Initial instinct to "share everything everywhere" was an early mistake
- Different parts need *intentionally different* views of the same state
- **Performance:** UI widgets need far more data than the model should see (images, pricing variants, preloaded options → token usage, latency, cognitive noise)
- **Logic:** Some information must remain asymmetric by design (e.g., game state where model knows the answer but user must not)
- Formalized using different tool output fields: `structuredContent` (visible to widget + model), `_meta` (widget only, hidden from model)

### Lesson 2: Lazy-Loading Doesn't Translate Well to AI Apps

- Web default of lazy-loading breaks down in AI context — tool calls imply multi-second delays
- **Front-load aggressively:** send as much data as possible in the initial tool response
- Hydrate widgets via `window.openai.toolOutput`
- Only use classic XHR when widget can safely fetch from public API without needing to share info with the model

### Lesson 3: The Model Needs Visibility

- When user interacts with widget then asks a question, model has no idea what user is looking at
- Solution: `window.openai.setWidgetState(state)` — store state data added to model's context on next interaction
- Advanced: Declarative `data-llm` attribute on components: `data-llm="User is viewing product details"` — Vite plugin scrapes these and auto-updates widgetState

### Lesson 4: Different Interactions Require Different APIs

Multiple interaction paths between widget, server, and model are NOT interchangeable. Be intentional about which mechanism is responsible for which part of the experience.

### Lesson 5: UI Must Adapt to Multiple Display Modes

ChatGPT Apps render in three modes: **inline** (in conversation, for quick interactions), **fullscreen** (entire screen with chat bar, for complex/maps), **picture-in-picture** (stays on top, for ongoing relevance during follow-ups). Account for device-specific safe zones and overlays.

### Lesson 6: UI Consistency Matters in Embedded Environments

Widgets live inside an existing interface — visual inconsistencies stand out immediately. Use the OpenAI Apps SDK UI Kit (Tailwind CSS based) for components, icons, and design tokens that align with ChatGPT's design system.

### Lesson 7: Language-First Filtering

Traditional dashboards with sidebars of checkboxes are a regression in agentic UI. When users can express intent in natural language ("Sunny destinations in Europe under $200"), forcing them through UI controls adds friction. Instead: provide the model with a **List of Values (LOV)** for tool parameters. Model maps natural language directly to backend API requirements.

### Lesson 8: Files Can Unlock Richer Interactions

Files shouldn't be secondary inputs — they can unlock new interactions. Example: user uploads product photo → model identifies it → continues into product matching in widget. Tools can consume files via `openai/fileParams`; widgets can use `window.openai.uploadFile` and `getFileDownloadUrl`.

### Lesson 9: CSPs Are the New CORS

OpenAI renders Apps inside a double-nested iframe with strict Content Security Policies. Must carefully declare allowed domains: `connectDomains` (API/XHR), `resourceDomains` (images, fonts, scripts), `frameDomains` (iframes), `redirectDomains` (external links without warnings). Treat CSP configuration as a first-class concern early.

### Lesson 10: Small Widget Flags Have Outsized Impact

- `widgetDomain` — required for submission, defines "Open in App" button location
- Tool annotations (`readOnly`, `destructiveHint`, `openWorldHint`) — required and validated during submission
- Tool visibility — tools not callable by model must be marked private
- `widgetAccessible` — controls whether widget can call tools using `callTool`

### Lesson 11: Fast Iteration Requires Hot Reload

Long-TTL resource caching and JSON-RPC forwarding makes standard HMR incompatible with ChatGPT Apps. Built a Vite plugin that intercepts resource requests and injects real-time updates into the ChatGPT iframe.

### Lesson 12: Not Every Test Belongs in ChatGPT

Local emulator that mocks the ChatGPT host environment with debugging tools and app-specific logs. Iterate on React state and layout in milliseconds, reserve real ChatGPT tests for validating model interactions and edge cases.

### Lesson 13: Mobile Testing Requires Explicit Support

Vite's default localhost makes tunnelled URLs inaccessible from other devices. Extended Vite plugin to support domain forwarding on tunnelled ports for iOS/Android testing.

### Lesson 14: Familiar Abstractions Speed Up Frontend Work

React-friendly abstractions: hooks like `useCallTool`, `useWidgetState`, `useLocale`; advanced state management with `createStore` (built on Zustand). Reduced boilerplate and made widget dev feel like modern web workflows.

### Lesson 15: Turn Lessons into Reusable Tooling

- **Skybridge Framework:** Open-source React framework with reusable hooks, dev tools (HMR, local emulator), and the `data-llm` attribute
- **Codex Skill for ChatGPT App Builder:** Covers full lifecycle — ideation, code generation, local testing, QA/publishing, deployment

---

## ARTICLE 4: Codex App Server — Technical Documentation

**Source:** [developers.openai.com/codex/app-server](https://developers.openai.com/codex/app-server/)

### Architecture Overview

- Open-source implementation in Rust: `codex-rs/app-server`
- Bidirectional JSON-RPC 2.0 protocol over stdio (JSONL), omitting `"jsonrpc":"2.0"` header
- Designed for deep integration in client products: auth, conversation history, approvals, streamed agent events
- Client bindings implemented in Go, Python, TypeScript, Swift, and Kotlin

### Core Primitives

1. **Thread:** A conversation between user and Codex agent. Contains turns. Can be created, resumed, forked, archived, compacted, rolled back.
2. **Turn:** A single user request and the agent work that follows. Contains items and streams incremental updates. Can be started, steered mid-flight, interrupted.
3. **Item:** A unit of input or output — user message, agent message, command run, file change, tool call, reasoning, plan, web search, image view, context compaction, review mode.

### Thread Lifecycle

- `thread/start` — create new conversation
- `thread/resume` — continue existing one
- `thread/fork` — branch history into new thread id
- `thread/read` — read stored thread without resuming
- `thread/list` — paginated history with filters (modelProviders, sourceKinds, archived)
- `thread/archive` / `thread/unarchive` — manage thread storage
- `thread/compact/start` — trigger history compaction
- `thread/rollback` — drop last N turns from in-memory context

### Turn Management

- `turn/start` — begin generation with user input, model/effort/personality/cwd/sandbox overrides
- `turn/steer` — append user input to active in-flight turn (no new turn created)
- `turn/interrupt` — cancel active turn
- Input types: text, image (URL), localImage (path), skill invocation

### Event Streaming

Turn events: `turn/started`, `turn/completed`, `turn/diff/updated`, `turn/plan/updated`, `thread/tokenUsage/updated`

Item lifecycle: `item/started`, `item/completed`

Item deltas (streamed): `item/agentMessage/delta`, `item/plan/delta`, `item/reasoning/summaryTextDelta`, `item/reasoning/textDelta`, `item/commandExecution/outputDelta`, `item/fileChange/outputDelta`

### Approval System

- Command execution approvals: `item/commandExecution/requestApproval` → client responds accept/decline
- File change approvals: `item/fileChange/requestApproval` → client responds accept/decline
- MCP tool-call approvals: `tool/requestUserInput` with Accept/Decline/Cancel options
- Approvals scoped by `threadId` and `turnId`

### Review System

`review/start` runs the Codex reviewer for a thread. Targets: `uncommittedChanges`, `baseBranch`, `commit`, `custom`. Delivery modes: `inline` (on existing thread) or `detached` (new review thread).

### Skills Integration

- Invoke by including `$<skill-name>` in text input + adding a `skill` input item with name and path
- `skills/list` to discover available skills scoped by cwds
- `skills/config/write` to enable/disable skills
- Skills metadata includes `interface` (displayName, shortDescription) and `dependencies` (env vars, MCP servers)

### Apps (Connectors)

- `app/list` to fetch available apps with pagination
- Invoke via `$<app-slug>` in text input + `mention` input item with `app://<id>` path
- Tool calls can require approval via `tool/requestUserInput`

### Authentication

Three modes: **API key**, **ChatGPT managed** (OAuth flow), **ChatGPT external tokens** (host app supplies JWT). Token refresh via `account/chatgptAuthTokens/refresh`. Rate limits via `account/rateLimits/read`.

### Configuration

- `config/read` — effective configuration after layering
- `config/value/write` — write single key/value to `config.toml`
- `config/batchWrite` — atomic batch edits
- `configRequirements/read` — requirements from `requirements.toml` and/or MDM

### Models & Features

- `model/list` — discover models with effort options, input modalities, personality support, upgrade recommendations
- `experimentalFeature/list` — feature flags with lifecycle stages (beta, underDevelopment, stable, deprecated, removed)
- `collaborationMode/list` — collaboration mode presets

### Command Execution

- `command/exec` — run single command under server sandbox without thread/turn
- Sandbox types: `dangerFullAccess`, `readOnly`, `workspaceWrite`, `externalSandbox`
- External sandbox: `networkAccess` as `restricted` or `enabled`

---

## ARTICLE 5: Unlocking the Codex Harness — How We Built the App Server

**Source:** [openai.com/index/unlocking-the-codex-harness](https://openai.com/index/unlocking-the-codex-harness/)

### Why It Was Built

- Codex exists across many surfaces: web app, CLI, IDE extension, macOS desktop app
- All powered by the same **Codex harness** — the agent loop and logic underlying all Codex experiences
- The App Server is the critical link: a client-friendly, bidirectional JSON-RPC API
- As adoption grew, internal teams and external partners wanted to embed the same harness in their own products
- Partners like JetBrains and Xcode wanted IDE-grade agent experiences; Desktop app needed to orchestrate many agents in parallel

### Design Evolution

- Codex CLI started as a TUI (terminal user interface)
- For VS Code extension, needed same harness to drive same agent loop from IDE UI
- First experimented with exposing Codex as an MCP server, but maintaining MCP semantics for VS Code proved difficult
- Landed on custom JSON-RPC protocol over stdio

### Architecture: Four Main Components

1. **Stdio Reader** — reads JSON-RPC input from stdin
2. **Codex Message Processor** — routes messages between client and core sessions
3. **Thread Manager** — spins up one core session for each thread
4. **Core Threads** — individual Codex core runtime instances

"Codex core" is both a library where all the agent code lives and a runtime that manages the persistence of one Codex thread.

### Transport

JSON-RPC over stdio (JSONL) across all surfaces. Makes it straightforward to build client bindings in any language.

### Conversation Primitives Design

- User/agent interaction is NOT a simple request/response
- One user request can unfold into a structured sequence: user input → agent incremental progress → artifacts (diffs, etc.)
- Landed on three core primitives (Thread, Turn, Item) with clear boundaries and lifecycles
- Makes interaction stream easy to integrate and resilient across different UIs

### Client Integration Pattern

- Local clients bundle or fetch a platform-specific App Server binary
- Launch as long-running child process
- Keep bidirectional stdio channel open for JSON-RPC
- VS Code extension and Desktop App ship with platform-specific Codex binary pinned to a tested version

### Key Capabilities Exposed

- Thread lifecycle and persistence (create, resume, fork, archive)
- Config and auth management (defaults, "Sign in with ChatGPT")
- Tool execution and extensions (shell/file tools in sandbox, MCP servers, skills)

---

## ARTICLE 6: Inside Our In-House Data Agent (Kepler)

**Source:** [openai.com/index/inside-our-in-house-data-agent](https://openai.com/index/inside-our-in-house-data-agent/)

### What Kepler Is

- Bespoke internal data agent powered by GPT-5.2
- Helps employees explore and reason over **600 petabytes of data**
- Conversational bridge between employees and the company's massive data platform
- Available wherever employees already work: **Slack agent, web interface, IDEs**
- Covers full analytics workflow: discovering data, running SQL, publishing notebooks and reports

### The Problem

- Over **70,000 datasets** in OpenAI's data platform
- Finding the correct table is a "needle in a haystack" problem
- Manual navigation leads to frustration and lost productivity
- Even with correct tables, producing correct results requires reasoning about relationships, transformations, filters

### Architecture: RAG-Based Table Discovery

- Uses **retrieval-augmented generation** instead of scanning raw metadata or logs
- Makes table understanding fast and scalable across tens of thousands of tables
- Keeps runtime latency predictable and low
- An **offline job compiles metadata** about each table, refreshed periodically without manual involvement
- Also uses codex generation to build metadata from code itself

### SQL Generation & Reasoning

- Agent reasons about table data and relationships to ensure transformations and filters are applied correctly
- Common failure modes handled: many-to-many joins, filter pushdown errors, unhandled nulls
- Relies on **schema metadata** (column names, data types) to inform SQL writing
- Uses **table lineage** (upstream/downstream relationships) to provide context on how tables relate

### Institutional Knowledge Integration

- Accesses **Slack, Google Docs, and Notion** for critical company context
- Context includes: launches, reliability incidents, internal codenames/tools, canonical definitions
- Documents are ingested, embedded, and stored with metadata and permissions
- Retrieval service handles access control and caching at runtime

### Six-Layer Context Architecture

- Uses Model Context Protocol (MCP) for tool communication
- Connects to Apache Spark and Airflow data warehouses
- Performs computations, generates visualizations, and executes data transformations through natural language

### Memory & Continuous Improvement

- "Memory is really the mechanism that helps the agent continuously learn and improve. Context will get you maybe 80-90% of the way there. But sometimes you need those final little corrections that are really hard to just infer."
- Stores all questions for follow-up thread continuation
- Keeps custom workflows for common question types (product analysis, data validation)
- Agent evaluates its own progress — if query fails or returns suspicious results, investigates error, adjusts approach, retries

### Self-Evaluation & Quality

- Uses the **Evals API** to "unit test" answers against golden sets to prevent regressions
- **Eval Grader** scores each answer by comparing delivered results to expected/correct results
- Comparison includes "wiggle room" for things that don't meaningfully impact the answer (different SQL, same result)
- Operates strictly within existing security model — users only access data they're authorized to see

### Availability & Surface Areas

- Slack agent
- Web interface
- IDE integration (e.g., Cursor)
- Mobile and remote clients
- Can web search for external information
- Understands internal company knowledge

### Impact

- Transformed how teams work across Engineering, Finance, and Go-To-Market
- Employees answer high-impact questions instantly
- NOT being commercialized — kept strictly internal

---

## ARTICLE 7: Unrolling the Codex Agent Loop

**Source:** [openai.com/index/unrolling-the-codex-agent-loop](https://openai.com/index/unrolling-the-codex-agent-loop/)
**Author:** Michael Bolin, Member of Technical Staff

### The Agent Loop Core Architecture

The agent loop is the core logic in Codex CLI responsible for orchestrating the interaction between the user, the model, and the tools the model invokes. This is the fundamental cycle:

1. Accept user input, construct textual prompt for model
2. Model generates response — either final answer or tool call request
3. If tool call: execute it, append output to prompt, query model again
4. Repeat until model emits done event with response message

An `AgentLoop.run()` function is the master loop: maintains a flat conversation log, feeds the current slice to the model, interprets result as text or tool call, hands tool calls to a tool-runner layer.

### System Prompt

- Long, detailed system prompt hardcoded in `src/utils/agent/agent-loop.ts`
- Tells model its role as Codex CLI, capabilities (shell, patching), constraints (sandboxing), coding guidelines
- Began as default GPT-5.1-Codex-Max prompt, further optimized against internal evals for: answer correctness, completeness, quality, correct tool usage and parallelism, bias for action

Key system prompt instructions include:
- "You are Codex, based on GPT-5. You are running as a coding agent in the Codex CLI on a user's computer."
- "You are an autonomous senior engineer: once the user gives a direction, proactively gather context, plan, implement, test, and refine without waiting for additional prompts at each step."
- "Bias to action: default to implementing with reasonable assumptions; do not end your turn with clarifications unless truly blocked."
- "Persist until the task is fully handled end-to-end."

### Tools: Shell & apply_patch

Almost everything exposed through two tools:

**Shell (`container.exec`):** General-purpose shell command executor. Model leverages familiar CLI utilities through a unified interface. Simplicity is the key — instead of learning multiple APIs, model uses standard shell commands.

**`apply_patch`:** Specific diff format for file editing. Instead of running as shell command, uses `execApplyPatch` → `process_patch` → Node.js `fs` calls to modify files directly. OpenAI strongly recommends using their exact apply_patch implementation as the model has been trained to excel at this diff format.

Additional tools: `update_plan` for planning/TODO items, web search, custom tools via MCP servers.

### Stateless Design

- Every request ships as **fully stateless** — entire conversation history travels with each API call
- Does NOT use `previous_response_id` parameter for stored conversation state
- Design simplifies things for API providers and supports customers who opt into Zero Data Retention (ZDR)
- Tradeoff: tool or config changes become a real cost since they can invalidate prompt caching

### Prompt Caching & Quadratic Growth

- **Major challenge:** LLM inference is "quadratic in terms of the amount of JSON sent to the Responses API over the course of the conversation"
- **Prompt caching is key:** by reusing output of previous inference call, inference performance becomes linear instead of quadratic
- Cache hits require **exact prefix matches** within prompts
- Must carefully avoid operations that trigger cache misses: changing available tools, switching models, modifying sandbox configuration mid-conversation
- These operations invalidate the cache and degrade performance

### Context Window Management & Compaction

- When token counts exceed a threshold, Codex automatically compacts conversations
- Earlier versions required manual compaction through a slash command
- Current system uses specialized API endpoint that compresses context while preserving summarized state
- Preserves key prior state through an encrypted content item with fewer conversation tokens
- Enables **multi-hour reasoning** without hitting context limits

### Sandboxing

**macOS:** Apple's Seatbelt profile restricts filesystem access to project directory, blocks all network access except to OpenAI's API.

**Linux:** Docker container with iptables firewall rules, restricting network access and filesystem scope.

**Cloud (Codex product):** Entirely within secure, isolated container. Internet access disabled during task execution. Agent can only interact with code from GitHub repos and pre-installed dependencies.

### Reasoning Effort

- **Medium:** Good all-around interactive coding model, balances intelligence and speed
- **High/xHigh:** For hardest tasks, long-running autonomy — Codex can work autonomously for hours
- codex-1 tested at max context length of 192k tokens and medium reasoning effort

### Prompt Engineering Insights

- System prompt is extensive — literally teaches the model a mini-API
- Explains exactly how to invoke tools and format outputs
- Bakes in safety and UX: default sandbox/no-network assumptions, clear approval gates for risky commands
- Instructs model to verify changes by running the project's own checks before declaring success
- Planning is **implicit** — Codex is nudged to iterate (read → edit → test) instead of producing big upfront plans
- The diff/approval path keeps humans in control

### Known Challenges

- Quadratic prompt growth as conversations extend
- Performance degradation from cache misses
- Inconsistent enumeration of MCP tools required patching
- Some users experienced infinite loops of file-related commands and context compaction

---

## CROSS-CUTTING THEMES & PATTERNS FOR YOUR PROJECT

### 1. Agent Environment Design > Agent Prompting

The biggest insight across all articles: **the quality of the environment determines the quality of agent output**, not just prompt engineering. Build rich environments with clear abstractions, well-structured knowledge bases, and proper tooling before expecting reliable agent work.

### 2. Skills as Living SOPs

Skills should encode your organization's standard operating procedures — procedures, templates, guardrails — that evolve as your org evolves. They reduce prompt spaghetti, load context only when needed, and create deterministic workflows when paired with explicit invocation.

### 3. Knowledge Architecture

- Keep instructions short (~100 lines) and treat them as a table of contents
- Store deep knowledge in structured directories (`docs/`, `memory/`)
- Automate knowledge freshness with linters, CI validation, and doc-gardening agents
- Everything the agent needs must be codified in accessible files — not in people's heads

### 4. Three-Body Context Management

In any system with users, UI, and models, deliberately decide who sees what. Use separate channels for model context vs. UI data. Front-load data aggressively to minimize latency from tool calls.

### 5. Build for Long Runs from Day One

- Design for container/session reuse across steps
- Use compaction as a default primitive, not emergency fallback
- Stateless architecture simplifies but creates caching challenges — avoid mid-conversation config changes
- Plan for quadratic growth and cache invalidation

### 6. Security Posture

- Network access: minimal allowlists at both org and request level
- Credentials: use domain_secrets/placeholders, never expose raw credentials to models
- Skills + networking = high-risk — design for containment
- Sandbox everything: filesystem restrictions, network restrictions, approval gates

### 7. Feedback Loops & Quality Gates

- Automated doc-gardening agents
- Linters and CI validating knowledge bases
- Eval Graders comparing against golden sets
- Self-evaluation: agents that check their own work and retry on failure
- Human approval gates for risky operations

### 8. The App Server Pattern

When building multi-surface agent experiences, create a single harness that powers all clients via a bidirectional RPC protocol. Design conversation primitives (Thread → Turn → Item) with clear lifecycles. Stream events for real-time UI updates. Support thread persistence, forking, archiving, and compaction.

### 9. Depth-First Approach

Don't try to build everything at once. Work depth-first: build foundational abstractions and building blocks first, then layer complexity. Break large goals into small blocks that the agent can construct, then use those blocks to unlock more complex tasks.

### 10. Eval Everything

Every article emphasizes evaluation: eval harnesses, eval graders, golden sets, regression tracking, A/B prompt variants, failure tagging, baseline/delta comparisons. Build evals into the system from the start — they're your safety net and improvement engine.
